{
  "hash": "2ab3ef3f242b92739699f2477c2e67c8",
  "result": {
    "markdown": "---\ntitle: \"Cross Validation\"\nauthor: \"paloma leonato\"\ndate: \"2023-11-19\"\ncategories: [R, regression, cross validation]\nimage: \"image.jpg\"\n---\n\n\n## Cross validation\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(caret)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: ggplot2\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: lattice\n```\n:::\n\n```{.r .cell-code}\nmydata <- ISLR2::Portfolio\n\nset.seed(1234)\ncontrol_kfold <- trainControl(method = \"cv\", number=10)\n\n\nkfold <-train(Y~X , data = mydata, method = \"lm\", trControl = control_kfold)\n\nkfold$results\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  intercept      RMSE Rsquared       MAE    RMSESD RsquaredSD     MAESD\n1      TRUE 0.9544015 0.319766 0.7846862 0.2192737  0.2138706 0.1840715\n```\n:::\n:::\n\n\nThis is not the best sample. But gets you the basics for the cross-validation. The training data is divided into 10 folds. Every time the model is created with 9 folds, one of the folds is left out to estimate the validation of the model. Once the model is created, you can validate your results with the model\\$results. In this case kfold\\$results.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}